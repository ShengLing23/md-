# Hadoop

## HDFS

### HDFS设计

​	HDFS以**流式数据访问模式**来存储超大文件。运行在商用硬件集群上。

* 超大文件：
* 流式数据访问：HDFS的构建思路：一次写入，多次读取是最高效的访问模式。
* 商用硬件

### HDFS的概念

#### 数据块

* 每个磁盘都有默认的数据库的大小，这是磁盘进行数据读写的最小单位。
* HDFS同样也有块（block）的概念。默认是128MB.
* HDFS上的文件也被划分为块大小的多个分块（chunk）,作为独立的存储单元。

#### namenode

​	HDFS集群有两类节点以管理节点—工作节点模式运行，即一个namenode（管理节点）和多个datanode（工作节点）。

​	namenode管理文件系统的命名空间。它维护着文件系统树及整棵树内所有的文件和目录。这些信息以两个文件形式永久保存在本地磁盘上：命名空间镜像文件和编辑日志文件。

​	namenode也记录着每个文件中各个块所在的数据节点信息，但它并不永久保存块的位置信息，因为这些信息会在系统启动时根据数据节点信息重建。

#### datanode

​	DataNode是文件系统的工作节点。它们根据需要存储并检索数据块（受客户端或namenode的调度），并且定期向namenode发送它们所存储的块的列表。

​	没有NameNode，文件系统将无法使用。如果namenode服务的机器毁坏，文件系统上的所有文件都会丢失，因为我们不知道如何根据datanode的块重建文件。因此对namenode的容错非常重要

#### 块缓存

​	通常datanode从磁盘中读取块，但对于访问频繁的文件，其对应的块可能被显式地缓存在datanode的内存中。默认情况下，一个块仅缓存在一个datanode的内存中，当然可以针对每个配置datanode的数量。

### HDFS命令

```shell
# 从本地文件系统将一个文件复制到HDFS
hadoop fs -copyFromLocal  sourcePath targetPath
```

# MapReduce

​	MapReduce是一种可以用于数据处理的编程模型。

​	MapReduce任务分为两个处理阶段：map阶段和reduce阶段。每个阶段都以键-值对作为输入和输出，其类型由程序员选择。

